{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de3691-8a15-4dc3-9a03-af9e2df91ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2890ee7-eaba-4bf3-b9cd-766bd689e097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/code_dilip/AI_and_ML/Machine-Learning/Deep_Learning/Neural_Networks_and_deep_Learning/Week 2/Logistic Regression as a Neural Network\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99702101-a1b7-4877-8da5-3879ac5ed51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/code_dilip/AI_and_ML/Machine-Learning/Deep_Learning/Neural_Networks_and_deep_Learning/Week 2/Logistic Regression as a Neural Network'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5501a41-09e8-4316-857b-9bb482f27468",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/code_dilip/AI_and_ML/Machine_Learning_intro/Deeplearning.ai_Neural_networks/aulas_keras/train_catvnoncat.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Loading the data (cat/non-cat)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes \u001b[38;5;241m=\u001b[39m load_dataset()\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/code_dilip/AI_and_ML/Machine_Learning_intro/Deeplearning.ai_Neural_networks/aulas_keras/train_catvnoncat.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     train_set_x_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_set_x\u001b[39m\u001b[38;5;124m\"\u001b[39m][:]) \u001b[38;5;66;03m# your train set features\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     train_set_y_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_set_y\u001b[39m\u001b[38;5;124m\"\u001b[39m][:]) \u001b[38;5;66;03m# your train set labels\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Machine-Learning/lib/python3.11/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/anaconda3/envs/Machine-Learning/lib/python3.11/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/code_dilip/AI_and_ML/Machine_Learning_intro/Deeplearning.ai_Neural_networks/aulas_keras/train_catvnoncat.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('/home/code_dilip/AI_and_ML/Machine_Learning_intro/Deeplearning.ai_Neural_networks/aulas_keras/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('/home/code_dilip/AI_and_ML/Machine_Learning_intro/Deeplearning.ai_Neural_networks/aulas_keras/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "# Loading the data (cat/non-cat)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994cf038-7483-4d2a-940d-537eae8c54c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/code_dilip/AI_and_ML/Machine_Learning_intro/Deeplearning.ai_Neural_networks/aulas_keras/train_catvnoncat.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the data (cat/non-cat)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes \u001b[38;5;241m=\u001b[39m load_dataset()\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/code_dilip/AI_and_ML/Machine_Learning_intro/Deeplearning.ai_Neural_networks/aulas_keras/train_catvnoncat.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     train_set_x_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_set_x\u001b[39m\u001b[38;5;124m\"\u001b[39m][:]) \u001b[38;5;66;03m# your train set features\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     train_set_y_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_set_y\u001b[39m\u001b[38;5;124m\"\u001b[39m][:]) \u001b[38;5;66;03m# your train set labels\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Machine-Learning/lib/python3.11/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/anaconda3/envs/Machine-Learning/lib/python3.11/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/code_dilip/AI_and_ML/Machine_Learning_intro/Deeplearning.ai_Neural_networks/aulas_keras/train_catvnoncat.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f87a3-2ec3-4c9c-8344-65567062610e",
   "metadata": {},
   "source": [
    "We added \"_orig\" at the end of image datasets (train and test) because we are going to preprocess them. After preprocessing, we will end up with train_set_x and test_set_x (the labels train_set_y and test_set_y don't need any preprocessing).\n",
    "\n",
    "Each line of your train_set_x_orig and test_set_x_orig is an array representing an image. You can visualize an example by running the following code. Feel free also to change the `index` value and re-run to see other images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba63aa6-5ef6-4c1f-8f9d-b8ae8526f1db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set_x_orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example of a picture\u001b[39;00m\n\u001b[1;32m      2\u001b[0m index \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(train_set_x_orig[index])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(train_set_y[\u001b[38;5;241m0\u001b[39m, index]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m classes[np\u001b[38;5;241m.\u001b[39msqueeze(train_set_y[:, index])]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m picture.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set_x_orig' is not defined"
     ]
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index =10\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[0, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35fc235c-a8d1-431e-8999-5bf6a096c2c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 209\n",
      "Number of testing examples: m_test = 50\n",
      "Height/Width of each image: num_px = 64\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_set_x shape: (209, 64, 64, 3)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x shape: (50, 64, 64, 3)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (≈ 3 lines of code)\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test =  test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc1660d-4d6a-4785-9180-6e76ee900dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set_x_orig\n",
    "Y_train = train_set_y\n",
    "X_test = test_set_x_orig\n",
    "Y_test = test_set_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b201e654-2838-4ae7-b6a1-c87ee820fd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (209, 64, 64, 3)\n",
      "Y_train.shape: (1, 209)\n",
      "\n",
      "X_test.shape: (50, 64, 64, 3)\n",
      "Y_test.shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape:\",X_train.shape)\n",
    "print(\"Y_train.shape:\",Y_train.shape)\n",
    "print()\n",
    "print(\"X_test.shape:\",X_test.shape)\n",
    "print(\"Y_test.shape:\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297e4bce-6dd9-43c2-8f17-d2509d3174b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_flatten.shape: (12288, 209)\n",
      "X_test_flatten.shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_flatten = X_train.reshape(X_train.shape[1]*X_train.shape[2]*X_train.shape[3],X_train.shape[0])\n",
    "X_test_flatten = X_test.reshape(X_test.shape[1]*X_test.shape[2]*X_test.shape[3],X_test.shape[0])\n",
    "print(\"X_train_flatten.shape:\",X_train_flatten.shape)\n",
    "print('X_test_flatten.shape:',X_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f7614f-9f09-4f66-8394-aa1a1d80badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34a8fd4e-ce55-437b-9942-cc561d2b0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "\n",
    "    W = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    return (W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f115f5d-48db-4507-be7d-6b16d215fa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0520fd1d-f892-41ff-80be-1922ceb22433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(W,b,X,Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    Z = np.dot(W.T,X)+b\n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    cost = (-1/m)*(np.dot(Y,np.log(A+1).T) + np.dot((1-Y),np.log((1-A)+1).T))\n",
    "    dW = (np.dot(X,(A-Y).T))/m\n",
    "    db = np.sum(A-Y)/m\n",
    "    gradients = {'dW':dW,'db':db}\n",
    "\n",
    "    return (gradients,cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be9ec9c2-72db-4072-8a04-1f16c696f09c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[0.99845601]\n",
      " [2.39507239]]\n",
      "db = 0.001455578136784208\n",
      "cost = [[-0.23252594]]\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w,b,X,Y)\n",
    "print (\"dw = \" + str(grads[\"dW\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7df1f3-60c5-4dad-8fbe-59d0c211fa9a",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  ** dw **  </td>\n",
    "      <td> [[ 0.99845601]\n",
    "     [ 2.39507239]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** db **  </td>\n",
    "        <td> 0.00145557813678 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** cost **  </td>\n",
    "        <td> 5.801545319394553 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13734602-12cc-44bd-ab54-786f8bbe5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(W,b,X,Y,num_iterations,learning_rate,print_cost):\n",
    "\n",
    "    costs = []\n",
    "    for i in range(1,num_iterations+1):\n",
    "        \n",
    "        (grads,cost) = propagate(W,b,X,Y)\n",
    "        dw = grads['dW']\n",
    "        db = grads['db']\n",
    "        W = W - (learning_rate*dw)\n",
    "        b = b - (learning_rate*db)\n",
    "        costs.append(cost)\n",
    "\n",
    "        if(i%100==0):\n",
    "            print(\"{}/{} iteration!\".format(i,num_iterations))\n",
    "            if(print_cost):\n",
    "                print(\"cost:\",cost)\n",
    "                \n",
    "        params = {'W':W,'b':b}\n",
    "    return (params,grads,costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1235a6e5-6064-40ed-9877-daf0ea19b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 iteration!\n",
      "w = [[0.19033591]\n",
      " [0.12259159]]\n",
      "b = 1.9253598300845747\n",
      "dw = [[0.67752042]\n",
      " [1.41625495]]\n",
      "db = 0.21919450454067654\n"
     ]
    }
   ],
   "source": [
    "(params,grads,costs) = optimize(w,b,X,Y,num_iterations=100,learning_rate=0.009,print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"W\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dW\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0964e8-3995-46a5-9636-3fee43adff7d",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style=\"width:40%\">\n",
    "    <tr>\n",
    "       <td> **w** </td>\n",
    "       <td>[[ 0.19033591] [ 0.12259159]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **b** </td>\n",
    "       <td> 1.92535983008 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **dw** </td>\n",
    "       <td> [[ 0.67752042]\n",
    " [ 1.41625495]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **db** </td>\n",
    "       <td> 0.219194504541 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "663d6547-2070-4ca9-8708-128ec5a29c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W,b,X):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    Z = np.dot(W.T,X)+b\n",
    "    A = sigmoid(Z)\n",
    "    Y_prediction = (A>=0.5)*1.0\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b34640a-ef87-4927-984c-65a01df8f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aef2ac93-07a7-4a18-ad55-ea73af0aa136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train,Y_train,X_test,Y_test,num_iterations,learning_rate,print_cost):\n",
    "\n",
    "    (W,b) = initialize_with_zeros(X_train.shape[0])\n",
    "    (parameters,grads,costs) = optimize(W,b,X_train,Y_train,num_iterations,learning_rate,print_cost)\n",
    "    (W,b) = (parameters['W'],parameters['b'])\n",
    "    Y_train_predict = predict(W,b,X_train)\n",
    "    Y_test_predict = predict(W,b,X_test)\n",
    "\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_train_predict - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_test_predict - Y_test)) * 100))\n",
    "\n",
    "    d = {'costs':costs,\n",
    "         'dW':grads['dW'],\n",
    "         'db':grads['db'],\n",
    "         'Y_prediction_train':Y_train_predict,\n",
    "         'Y_prediction_test':Y_test_predict,\n",
    "         'learning_rate':learning_rate,\n",
    "         'num_iterations':num_iterations}\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13ca3807-a29e-47cc-86ac-489fd6561fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def z_score_normalization(x):\n",
    "    mu = np.mean(x,axis=0)\n",
    "    sigma = np.std(x,axis=0)\n",
    "    x_norm = (x - mu)/sigma\n",
    "    return (mu,sigma,x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aaba114-74e0-448f-9f8e-2ded5b7e3d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_norm.shape: (12288, 209)\n",
      "x_test_norm.shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "(mu_tr,sigma_tr,X_train_norm) = z_score_normalization(X_train_flatten)\n",
    "(mu_t,sigma_t,X_test_norm) = z_score_normalization(X_test_flatten)\n",
    "print(\"x_train_norm.shape:\",X_train_norm.shape)\n",
    "print(\"x_test_norm.shape:\",X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ae417c4-5dfd-415d-8cc1-befa86085b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/2000 iteration!\n",
      "cost: [[-0.37601324]]\n",
      "200/2000 iteration!\n",
      "cost: [[-0.48892864]]\n",
      "300/2000 iteration!\n",
      "cost: [[-0.51183728]]\n",
      "400/2000 iteration!\n",
      "cost: [[-0.54949121]]\n",
      "500/2000 iteration!\n",
      "cost: [[-0.64403684]]\n",
      "600/2000 iteration!\n",
      "cost: [[-0.66657023]]\n",
      "700/2000 iteration!\n",
      "cost: [[-0.67285342]]\n",
      "800/2000 iteration!\n",
      "cost: [[-0.67572757]]\n",
      "900/2000 iteration!\n",
      "cost: [[-0.67751477]]\n",
      "1000/2000 iteration!\n",
      "cost: [[-0.67880435]]\n",
      "1100/2000 iteration!\n",
      "cost: [[-0.67981224]]\n",
      "1200/2000 iteration!\n",
      "cost: [[-0.68063823]]\n",
      "1300/2000 iteration!\n",
      "cost: [[-0.68133644]]\n",
      "1400/2000 iteration!\n",
      "cost: [[-0.68193967]]\n",
      "1500/2000 iteration!\n",
      "cost: [[-0.68246943]]\n",
      "1600/2000 iteration!\n",
      "cost: [[-0.68294061]]\n",
      "1700/2000 iteration!\n",
      "cost: [[-0.68336397]]\n",
      "1800/2000 iteration!\n",
      "cost: [[-0.68374755]]\n",
      "1900/2000 iteration!\n",
      "cost: [[-0.68409752]]\n",
      "2000/2000 iteration!\n",
      "cost: [[-0.68441872]]\n",
      "train accuracy: 100.0 %\n",
      "test accuracy: 52.0 %\n"
     ]
    }
   ],
   "source": [
    "d = model(X_train_norm, Y_train, X_test_norm, Y_test, num_iterations = 2000, learning_rate = 0.0099, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9e864-af69-49a8-884e-c9e23eddb0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
